---
title: Demystifying LLMs
---

# Demystifying LLMs

Welcome! Today, let's explore how Large Language Models (LLMs) work and how you can build powerful AI apps.

---

# Next Word Prediction Game

Let's play a quick game! I'll start a sentence, and you try to guess the next word.

_Example:_

> The cat sat on the \_\_\_

(Wait for audience responses)

---

# How Do LLMs Work?

- LLMs predict the next word in a sequence, just like our game
- Trained on massive datasets
- Use neural networks (transformers)
- Can generate, summarize, translate, and answer questions

---

# Building Enterprise Apps with LLMs

- LLMs can automate workflows, answer questions, and more
- Challenges: context, memory, reliability
- Need for tools to manage state and context

---

# Why VectorStore and Tool Callbacks?

- VectorStore: manages conversation state and memory
- Tool callbacks: let LLMs interact with external systems (APIs, databases)
- Enables more powerful, context-aware apps

---

# MCP, Agents, and Chatbots

- Model Context Protocol (MCP): standard for LLM tool use
- Agents: LLMs that can plan, reason, and use tools
- Chatbots: user-facing apps powered by LLMs and agents

---

# Case Study: PDP-HELPER for Opencast (Spring AI)

- Built with Spring AI
- Helps users with Product Detail Pages (PDP)
- Integrates LLMs, tools, and enterprise data

---

# Build Your Own Chatbots!

- LLMs are accessible to everyone
- Start small, experiment, and iterate
- Encourage you to build your own AI-powered apps!

---

# Thank You!

Questions? Let's connect and build the future of AI together.

---

# Resources

- [Slidev](https://sli.dev)
- [Spring AI](https://docs.spring.io/spring-ai)
- [OpenAI](https://openai.com)
- [LangChain](https://langchain.com)
- [Opencast](https://opencast.org)
